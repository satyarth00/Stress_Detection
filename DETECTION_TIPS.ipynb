{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb77523-52d1-423b-8bbf-56cc904828aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting keras\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sehga\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\sehga\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sehga\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sehga\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 7.6/376.0 MB 36.2 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 16.3/376.0 MB 38.0 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 22.5/376.0 MB 36.6 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 25.4/376.0 MB 30.4 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 27.5/376.0 MB 26.4 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 30.9/376.0 MB 24.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 33.6/376.0 MB 22.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 35.9/376.0 MB 21.1 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 38.0/376.0 MB 20.0 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 41.2/376.0 MB 19.2 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 44.8/376.0 MB 19.0 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 47.7/376.0 MB 18.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 50.6/376.0 MB 18.2 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 53.2/376.0 MB 17.7 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 56.1/376.0 MB 17.5 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 58.5/376.0 MB 17.2 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 61.3/376.0 MB 16.9 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 64.0/376.0 MB 16.7 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 66.8/376.0 MB 16.6 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 69.7/376.0 MB 16.4 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 71.8/376.0 MB 16.0 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 74.7/376.0 MB 15.9 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 78.4/376.0 MB 15.9 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 80.5/376.0 MB 15.8 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 83.6/376.0 MB 15.7 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 86.5/376.0 MB 15.6 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 89.1/376.0 MB 15.5 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 92.0/376.0 MB 15.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 94.1/376.0 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 97.0/376.0 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 100.1/376.0 MB 15.2 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 102.8/376.0 MB 15.1 MB/s eta 0:00:19\n",
      "   ---------- ---------------------------- 105.6/376.0 MB 15.1 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 108.3/376.0 MB 15.0 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 110.9/376.0 MB 14.9 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 113.8/376.0 MB 14.9 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 116.7/376.0 MB 14.8 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 119.5/376.0 MB 14.8 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 122.4/376.0 MB 14.8 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 124.8/376.0 MB 14.7 MB/s eta 0:00:18\n",
      "   ------------- ------------------------- 127.9/376.0 MB 14.7 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 130.3/376.0 MB 14.6 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 132.9/376.0 MB 14.6 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 136.1/376.0 MB 14.6 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 138.4/376.0 MB 14.5 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 141.0/376.0 MB 14.4 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 143.9/376.0 MB 14.5 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 146.8/376.0 MB 14.4 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 149.4/376.0 MB 14.4 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 152.6/376.0 MB 14.4 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 155.2/376.0 MB 14.4 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 158.1/376.0 MB 14.3 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 160.7/376.0 MB 14.3 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 163.6/376.0 MB 14.3 MB/s eta 0:00:15\n",
      "   ----------------- --------------------- 166.2/376.0 MB 14.3 MB/s eta 0:00:15\n",
      "   ----------------- --------------------- 169.1/376.0 MB 14.2 MB/s eta 0:00:15\n",
      "   ----------------- --------------------- 171.7/376.0 MB 14.2 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 173.5/376.0 MB 14.1 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 176.2/376.0 MB 14.1 MB/s eta 0:00:15\n",
      "   ------------------ -------------------- 179.6/376.0 MB 14.1 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 183.2/376.0 MB 14.1 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 185.6/376.0 MB 14.1 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 188.5/376.0 MB 14.1 MB/s eta 0:00:14\n",
      "   ------------------- ------------------- 191.1/376.0 MB 14.1 MB/s eta 0:00:14\n",
      "   -------------------- ------------------ 194.0/376.0 MB 14.0 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 197.1/376.0 MB 14.1 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 199.8/376.0 MB 14.0 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 202.6/376.0 MB 14.0 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 205.3/376.0 MB 14.0 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 208.1/376.0 MB 14.0 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 210.8/376.0 MB 14.0 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 213.6/376.0 MB 14.0 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 216.5/376.0 MB 14.0 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 218.9/376.0 MB 13.9 MB/s eta 0:00:12\n",
      "   ----------------------- --------------- 221.8/376.0 MB 13.9 MB/s eta 0:00:12\n",
      "   ----------------------- --------------- 225.2/376.0 MB 13.9 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 227.5/376.0 MB 13.9 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 230.4/376.0 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 233.0/376.0 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 235.7/376.0 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------------------ -------------- 238.0/376.0 MB 13.8 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 241.7/376.0 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 244.1/376.0 MB 13.8 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 246.9/376.0 MB 13.8 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 249.8/376.0 MB 13.8 MB/s eta 0:00:10\n",
      "   -------------------------- ------------ 252.4/376.0 MB 13.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 255.6/376.0 MB 13.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 258.5/376.0 MB 13.8 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 260.8/376.0 MB 13.8 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 263.7/376.0 MB 13.7 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 265.8/376.0 MB 13.6 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 268.4/376.0 MB 13.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 272.1/376.0 MB 13.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 274.7/376.0 MB 13.3 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 277.6/376.0 MB 13.2 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 280.5/376.0 MB 13.2 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 282.9/376.0 MB 13.1 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 285.5/376.0 MB 13.0 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 288.1/376.0 MB 13.0 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 291.5/376.0 MB 13.1 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 294.4/376.0 MB 13.0 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 296.7/376.0 MB 13.0 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 299.9/376.0 MB 13.1 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 302.8/376.0 MB 13.1 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 305.9/376.0 MB 13.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 308.5/376.0 MB 13.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 311.2/376.0 MB 13.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 314.0/376.0 MB 13.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 316.7/376.0 MB 13.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 319.6/376.0 MB 13.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 321.9/376.0 MB 13.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 324.3/376.0 MB 13.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 327.4/376.0 MB 13.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 330.6/376.0 MB 13.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 332.7/376.0 MB 13.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 335.8/376.0 MB 13.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 339.0/376.0 MB 13.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 341.8/376.0 MB 13.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 345.0/376.0 MB 13.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 347.9/376.0 MB 13.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 350.5/376.0 MB 13.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 353.6/376.0 MB 13.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 356.0/376.0 MB 13.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 358.9/376.0 MB 13.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 361.8/376.0 MB 13.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 364.1/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  367.5/376.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  369.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.0/376.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.4/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 6.9 MB/s eta 0:00:00\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 18.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/26.4 MB 19.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.8/26.4 MB 20.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.8/26.4 MB 20.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 20.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 23.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 19.7 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, opencv-python, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.9 opencv-python-4.11.0.86 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras opencv-python numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039b22c9-feb5-4f73-815f-3a2e26b38348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e864d61-ada6-4db5-9bc2-f61248c4b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# 📁 Section 2: Load and Preprocess Image Dataset from Folders\n",
    "# --------------------------------------------\n",
    "# Folder structure:\n",
    "# - train/\n",
    "#   - Angry/\n",
    "#   - Disgust/\n",
    "#   - Fear/\n",
    "#   - Happy/\n",
    "#   - Neutral/\n",
    "#   - Sad/\n",
    "#   - Surprise/\n",
    "# - test/\n",
    "#   - Same structure as train/\n",
    "\n",
    "img_width, img_height = 48, 48\n",
    "batch_size = 64\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the base directory where 'train' and 'test' folders are located\n",
    "base_dir = r'C:/Users/sehga/Downloads/archive (1)'\n",
    "train_data_dir = os.path.join(base_dir, 'train')\n",
    "test_data_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8851d3bb-98db-4979-acf3-2f91ab59111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\sehga\n",
      "Folders in current directory: ['.anaconda', '.bash_history', '.conda', '.condarc', '.continuum', '.git', '.git-for-windows-updater', '.gitconfig', '.ipynb_checkpoints', '.ipython', '.jupyter', '.keras', '.lesshst', '.matplotlib', '.node_repl_history', '.vscode', '3D Objects', 'anaconda3', 'anaconda_projects', 'AppData', 'Application Data', 'Contacts', 'Cookies', 'DETECTION.ipynb', 'Documents', 'Downloads', 'E-Commerce(Data analyst).ipynb', 'Favorites', 'H', 'IBM_2.ipynb', 'IBM_3.ipynb', 'IBM_4.ipynb', 'IBM_5.ipynb', 'IBM_6.ipynb', 'IBM_FINAL_MODULE-1.ipynb', 'IBM_Practice.ipynb', 'index.html', 'Instructor.db', 'IntelGraphicsProfiles', 'java', 'Links', 'Local Settings', 'MasteringPython.ipynb', 'Message', 'module2_assessment', 'Music', 'My Documents', 'NetHood', 'node_modules', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TM.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OLA.ipynb', 'OneDrive', 'package-lock.json', 'package.json', 'Pizza.ipynb', 'Postman', 'Postman Agent', 'PrintHood', 'README.md', 'Recent', 'Saved Games', 'Searches', 'SendTo', 'socioeconomic.db', 'SQLiteMagic.db', 'SQL_IBM_MODULE.ipynb', 'SQL_MOD_1.ipynb', 'SQL_PYTHON_DATABASE.ipynb', 'Start Menu', 'Templates', 'Tracing', 'Untitled.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'venv', 'Videos']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(\"Current directory:\", os.getcwd()) \n",
    "print(\"Folders in current directory:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce8b8c4-250b-40c9-abcb-184fa58b43db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sehga\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m590,336\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m3,591\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,478,727</span> (17.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,478,727\u001b[0m (17.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,474,759</span> (17.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,474,759\u001b[0m (17.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> (15.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,968\u001b[0m (15.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# 🧠 Section 3: Build the CNN Model\n",
    "# --------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146d661c-f3d5-4c47-bc77-4a181268ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sehga\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1228s\u001b[0m 3s/step - accuracy: 0.2216 - loss: 2.0606 - val_accuracy: 0.1718 - val_loss: 1.9534\n",
      "Epoch 2/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m962s\u001b[0m 2s/step - accuracy: 0.2998 - loss: 1.8147 - val_accuracy: 0.3480 - val_loss: 1.7040\n",
      "Epoch 3/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 2s/step - accuracy: 0.3513 - loss: 1.6973 - val_accuracy: 0.3626 - val_loss: 1.7044\n",
      "Epoch 4/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 1s/step - accuracy: 0.3868 - loss: 1.5941 - val_accuracy: 0.4087 - val_loss: 1.5491\n",
      "Epoch 5/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 1s/step - accuracy: 0.4158 - loss: 1.5310 - val_accuracy: 0.4354 - val_loss: 1.4762\n",
      "Epoch 6/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 2s/step - accuracy: 0.4345 - loss: 1.4775 - val_accuracy: 0.4306 - val_loss: 1.5519\n",
      "Epoch 7/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.4627 - loss: 1.4005 - val_accuracy: 0.4720 - val_loss: 1.3803\n",
      "Epoch 8/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 1s/step - accuracy: 0.4863 - loss: 1.3502 - val_accuracy: 0.4961 - val_loss: 1.3336\n",
      "Epoch 9/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 957ms/step - accuracy: 0.5014 - loss: 1.3011 - val_accuracy: 0.5262 - val_loss: 1.2448\n",
      "Epoch 10/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 2s/step - accuracy: 0.5198 - loss: 1.2694 - val_accuracy: 0.5361 - val_loss: 1.2397\n",
      "Epoch 11/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 2s/step - accuracy: 0.5317 - loss: 1.2230 - val_accuracy: 0.5145 - val_loss: 1.3036\n",
      "Epoch 12/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 2s/step - accuracy: 0.5406 - loss: 1.2116 - val_accuracy: 0.5591 - val_loss: 1.1664\n",
      "Epoch 13/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 1s/step - accuracy: 0.5602 - loss: 1.1747 - val_accuracy: 0.5706 - val_loss: 1.1296\n",
      "Epoch 14/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 1s/step - accuracy: 0.5658 - loss: 1.1537 - val_accuracy: 0.5750 - val_loss: 1.1201\n",
      "Epoch 15/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 1s/step - accuracy: 0.5728 - loss: 1.1261 - val_accuracy: 0.5612 - val_loss: 1.1743\n",
      "Epoch 16/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.5899 - loss: 1.0903 - val_accuracy: 0.5756 - val_loss: 1.1291\n",
      "Epoch 17/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 1s/step - accuracy: 0.6025 - loss: 1.0606 - val_accuracy: 0.5894 - val_loss: 1.0789\n",
      "Epoch 18/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m526s\u001b[0m 1s/step - accuracy: 0.6100 - loss: 1.0377 - val_accuracy: 0.5915 - val_loss: 1.0769\n",
      "Epoch 19/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 1s/step - accuracy: 0.6078 - loss: 1.0454 - val_accuracy: 0.5935 - val_loss: 1.0935\n",
      "Epoch 20/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.6205 - loss: 1.0111 - val_accuracy: 0.5957 - val_loss: 1.0831\n",
      "Epoch 21/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 954ms/step - accuracy: 0.6302 - loss: 0.9772 - val_accuracy: 0.6077 - val_loss: 1.0455\n",
      "Epoch 22/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 1s/step - accuracy: 0.6389 - loss: 0.9602 - val_accuracy: 0.6042 - val_loss: 1.0646\n",
      "Epoch 23/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 1s/step - accuracy: 0.6484 - loss: 0.9337 - val_accuracy: 0.6188 - val_loss: 1.0431\n",
      "Epoch 24/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 1s/step - accuracy: 0.6548 - loss: 0.9232 - val_accuracy: 0.6087 - val_loss: 1.0668\n",
      "Epoch 25/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 1s/step - accuracy: 0.6628 - loss: 0.9036 - val_accuracy: 0.6216 - val_loss: 1.0367\n",
      "Epoch 26/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 2s/step - accuracy: 0.6684 - loss: 0.8796 - val_accuracy: 0.6102 - val_loss: 1.0792\n",
      "Epoch 27/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 2s/step - accuracy: 0.6797 - loss: 0.8630 - val_accuracy: 0.6286 - val_loss: 1.0408\n",
      "Epoch 28/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 2s/step - accuracy: 0.6841 - loss: 0.8404 - val_accuracy: 0.6283 - val_loss: 1.0250\n",
      "Epoch 29/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 2s/step - accuracy: 0.6959 - loss: 0.8166 - val_accuracy: 0.6304 - val_loss: 1.0388\n",
      "Epoch 30/30\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 1s/step - accuracy: 0.7014 - loss: 0.7937 - val_accuracy: 0.6389 - val_loss: 1.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved as model.h5\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# 🚀 Section 4: Train and Save Model\n",
    "# --------------------------------------------\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "model.save(\"model.h5\")\n",
    "print(\"✅ Model trained and saved as model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01de3f-9d6b-4911-bbb4-7fd790267680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 👁 Section 5: Real-Time Emotion Detection (Webcam — Improved with Suggestions)\n",
    "# --------------------------------------------\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "classifier = load_model(\"model.h5\")\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"📷 Starting webcam stream. Press Ctrl+C to stop.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_gray = cv2.resize(roi_gray, (48,48))\n",
    "            roi = roi_gray.astype('float32') / 255.0\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "            roi = np.expand_dims(roi, axis=-1)\n",
    "\n",
    "            prediction = classifier.predict(roi)[0]\n",
    "            emotion = emotion_labels[np.argmax(prediction)]\n",
    "\n",
    "            # Stress level and suggestion based on specific emotion\n",
    "            if emotion in ['Fear', 'Angry', 'Sad']:\n",
    "                stress_level = \"Highly Stressed\"\n",
    "            elif emotion in ['Disgust', 'Neutral']:\n",
    "                stress_level = \"Low Stressed\"\n",
    "            else:\n",
    "                stress_level = \"Not Stressed\"\n",
    "\n",
    "            # Activity suggestion\n",
    "            if emotion == 'Sad':\n",
    "                suggestion = \"Tip - Watch a movie or talk to a loved one.\"\n",
    "            elif emotion == 'Angry':\n",
    "                suggestion = \"Tip - Try deep breathing or meditation.\"\n",
    "            elif emotion == 'Fear':\n",
    "                suggestion = \"Tip - Take a break and talk to someone you trust.\"\n",
    "            elif emotion == 'Disgust':\n",
    "                suggestion = \"Tip - Do something creative to shift your focus.\"\n",
    "            elif emotion == 'Neutral':\n",
    "                suggestion = \"Tip - Relax with a book or music.\"\n",
    "            elif emotion == 'Happy':\n",
    "                suggestion = \"Tip - Keep spreading positivity!\"\n",
    "            elif emotion == 'Surprise':\n",
    "                suggestion = \"Tip - Share your excitement with friends!\"\n",
    "\n",
    "            label = f\"{emotion} ({stress_level})\"\n",
    "\n",
    "            # Drawing rectangles and putting text\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,255), 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "            cv2.putText(frame, suggestion, (x, y+h+30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(rgb)\n",
    "        clear_output(wait=True)\n",
    "        display(img)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"👋 Stopped by user\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"✅ Webcam released\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435bfa4-8c05-49f8-a50a-d5afa4d7a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d618654-17fe-4efb-9ead-7e26be86e523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
